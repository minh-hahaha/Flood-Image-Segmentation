{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emZ5ss_i8uM8",
   "metadata": {
    "id": "emZ5ss_i8uM8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a09dc6a",
   "metadata": {
    "id": "3a09dc6a"
   },
   "source": [
    "\n",
    "# Flood Segmentation — FloodNet **Supervised v1.0**\n",
    "\n",
    "\n",
    "\n",
    "This version is hard-wired for the real FloodNet layout:\n",
    "\n",
    "```\n",
    ".../FloodNet-Supervised_v1.0/\n",
    "  train/{train-org-img, train-label-img}\n",
    "  val/{val-org-img, val-label-img}\n",
    "  test/{test-org-img, test-label-img}\n",
    "```\n",
    "\n",
    "It **prints progress at every stage** and includes sanity checks so you can confirm files are matched correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m696.3/983.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hMounted at /content/drive\n",
      "Step: Data input folders\n",
      "Train IMG: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/train/train-org-img   Good\n",
      "Train MSK: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/train/train-label-img   Good\n",
      "Val   IMG: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/val/val-org-img   Good\n",
      "Val   MSK: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/val/val-label-img   Good\n",
      "Test  IMG: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/test/test-org-img   Good\n",
      "Test  MSK: /content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0/test/test-label-img   Good\n",
      "Sample train images: []\n",
      "Sample train masks:  ['10165_lab.png', '10166_lab.png', '10168_lab.png', '10170_lab.png', '10171_lab.png']\n"
     ]
    }
   ],
   "source": [
    "# If you're on Colab, uncomment:\n",
    "!pip -q install torch torchmetrics torchvision torchaudio opencv-python scikit-learn matplotlib\n",
    "\n",
    "\n",
    "import os, random, time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    ROOT_DIR: str = \"/content/drive/MyDrive/FloodNet/FloodNet-Supervised_v1.0\"\n",
    "    PALETTE_XLSX: str = \"/content/drive/MyDrive/FloodNet/ColorMasks-FloodNetv1.0/ColorPalette-Values.xlsx\"\n",
    "\n",
    "    # Optional: palette excel (class names + colors). You can keep using the one from the ColorMasks download:\n",
    "\n",
    "    NUM_CLASSES: int = 10\n",
    "    INPUT_SIZE: int = 512\n",
    "    BATCH_SIZE: int = 4\n",
    "    EPOCHS: int = 15\n",
    "    LR: float = 1e-4\n",
    "    NUM_WORKERS: int = 2 # Set this to a higher value for faster data loading\n",
    "    USE_PRETRAINED: bool = True\n",
    "    OUT_DIR: str = \"./outputs_floodnet_supervised\"\n",
    "\n",
    "cfg = CFG()\n",
    "os.makedirs(cfg.OUT_DIR, exist_ok=True)\n",
    "# SAFE MODE: avoid Windows notebook hangs\n",
    "# cfg.NUM_WORKERS = 0   # <- important\n",
    "PIN_MEMORY = False    # we'll pass this into DataLoaders\n",
    "\n",
    "# (optional) reduce batch size temporarily to speed up first batch\n",
    "cfg.BATCH_SIZE = 2\n",
    "\n",
    "# (optional) reduce epochs for initial check\n",
    "cfg.EPOCHS = 15\n",
    "\n",
    "# (optional) avoid OpenCV thread contention\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Resolve real FloodNet paths\n",
    "TRAIN_IMG_DIR = str(Path(cfg.ROOT_DIR) / \"train\" / \"train-org-img\")\n",
    "TRAIN_MSK_DIR = str(Path(cfg.ROOT_DIR) / \"train\" / \"train-label-img\")\n",
    "VAL_IMG_DIR   = str(Path(cfg.ROOT_DIR) / \"val\" / \"val-org-img\")\n",
    "VAL_MSK_DIR   = str(Path(cfg.ROOT_DIR) / \"val\" / \"val-label-img\")\n",
    "TEST_IMG_DIR  = str(Path(cfg.ROOT_DIR) / \"test\" / \"test-org-img\")\n",
    "TEST_MSK_DIR  = str(Path(cfg.ROOT_DIR) / \"test\" / \"test-label-img\")\n",
    "\n",
    "print(\"Step: Data input folders\")\n",
    "for t, p in [\n",
    "    (\"Train IMG\", TRAIN_IMG_DIR), (\"Train MSK\", TRAIN_MSK_DIR),\n",
    "    (\"Val   IMG\", VAL_IMG_DIR),   (\"Val   MSK\", VAL_MSK_DIR),\n",
    "    (\"Test  IMG\", TEST_IMG_DIR),  (\"Test  MSK\", TEST_MSK_DIR),\n",
    "]:\n",
    "    print(f\"{t}: {p}  \", \"Good\" if Path(p).exists() else \"Bad\")\n",
    "\n",
    "# Quick peek at some files (non-fatal if empty)\n",
    "def _peek(globpat, n=5):\n",
    "    xs = sorted(glob(globpat))[:n]\n",
    "    return [Path(x).name for x in xs]\n",
    "\n",
    "print(\"Sample train images:\", _peek(str(Path(TRAIN_IMG_DIR) / \"*.png\")))\n",
    "print(\"Sample train masks: \", _peek(str(Path(TRAIN_MSK_DIR) / \"*_lab.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5989cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Loaded palette\n",
      "   0: background             (0, 0, 0)\n",
      "   1: building-flooded       (255, 0, 0)\n",
      "   2: building-non-flooded   (180, 120, 120)\n",
      "   3: road-flooded           (160, 150, 20)\n",
      "   4: road-non-flooded       (140, 140, 140)\n",
      "   5: water                  (61, 230, 250)\n",
      "   6: tree                   (0, 82, 255)\n",
      "   7: vehicle                (255, 0, 245)\n",
      "   8: pool                   (255, 235, 0)\n",
      "   9: grass                  (4, 250, 7)\n"
     ]
    }
   ],
   "source": [
    "def load_palette_from_excel(xlsx_path):\n",
    "    if not Path(xlsx_path).exists():\n",
    "        names = ['background','building-flooded','building-non-flooded','road-flooded','road-non-flooded','water','tree','vehicle','pool','grass']\n",
    "        colors = [(0,0,0),(255,0,0),(180,120,120),(160,150,20),(140,140,140),(61,230,250),(0,82,255),(255,0,245),(255,235,0),(4,250,7)]\n",
    "        return {tuple(c):i for i,c in enumerate(colors)}, names, colors\n",
    "    df = pd.read_excel(xlsx_path, header=None)\n",
    "    rows = df[[6,7]].dropna()\n",
    "    names, colors = [], []\n",
    "    for _, row in rows.iterrows():\n",
    "        name = str(row[6]).strip()\n",
    "        rgb = row[7]\n",
    "        if isinstance(rgb, str):\n",
    "            rgb = tuple(int(x.strip()) for x in rgb.strip(\"() \").split(\",\"))\n",
    "        else:\n",
    "            rgb = tuple(int(x) for x in rgb)\n",
    "        names.append(name); colors.append(rgb)\n",
    "    return {tuple(c):i for i,c in enumerate(colors)}, names, colors\n",
    "\n",
    "PALETTE_MAP, CLASS_NAMES, CLASS_COLORS = load_palette_from_excel(cfg.PALETTE_XLSX)\n",
    "print(\"Step: Loaded palette\")\n",
    "for i,(n,c) in enumerate(zip(CLASS_NAMES, CLASS_COLORS)):\n",
    "    print(f\"  {i:2d}: {n:22s} {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d159f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Building dataloaders...\n",
      "Found 1460 pairs in train. Missing matches for 0 masks.\n",
      "Found 450 pairs in val. Missing matches for 0 masks.\n",
      "Data ready.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SUFFIXES = (\".png\",\".jpg\",\".jpeg\",\".tif\",\".tiff\")\n",
    "IMAGE_GUESS_PATTERNS = [\"{id}.png\",\"{id}.jpg\",\"{id}_img.png\",\"{id}_pre.png\",\"{id}_sat.png\",\"{id}_rgb.png\"]\n",
    "\n",
    "def basename_id(p: str):\n",
    "    name = Path(p).name\n",
    "    if \"_lab\" in name:\n",
    "        return name.split(\"_lab\")[0]\n",
    "    return Path(p).stem\n",
    "\n",
    "def find_rgb_for_id(image_dir: str, base: str):\n",
    "    for pat in IMAGE_GUESS_PATTERNS:\n",
    "        cand = Path(image_dir)/pat.format(id=base)\n",
    "        if cand.exists():\n",
    "            return str(cand)\n",
    "    for ext in IMAGE_SUFFIXES:\n",
    "        c = Path(image_dir)/(base+ext)\n",
    "        if c.exists():\n",
    "            return str(c)\n",
    "    hits = []\n",
    "    for ext in IMAGE_SUFFIXES:\n",
    "        hits += glob(str(Path(image_dir)/f\"{base}*{ext}\"))\n",
    "    return hits[0] if hits else None\n",
    "\n",
    "def rgb_mask_to_index(mask_bgr: np.ndarray):\n",
    "    mask_rgb = mask_bgr[:,:,::-1]\n",
    "    out = np.full(mask_rgb.shape[:2], 255, np.uint8)  # 255 ignore\n",
    "    for (r,g,b), idx in PALETTE_MAP.items():\n",
    "        m = (mask_rgb[:,:,0]==r) & (mask_rgb[:,:,1]==g) & (mask_rgb[:,:,2]==b)\n",
    "        out[m] = idx\n",
    "    return out\n",
    "\n",
    "class FloodNetDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, split, size=512, augment=False):\n",
    "        self.img_dir, self.mask_dir, self.split = img_dir, mask_dir, split\n",
    "        self.size, self.augment = size, augment\n",
    "        self.mask_paths = sorted(glob(str(Path(mask_dir) / \"*.png\")))\n",
    "        self.pairs = []\n",
    "        misses = 0\n",
    "        for mp in self.mask_paths:\n",
    "            base = basename_id(mp)\n",
    "            ip = find_rgb_for_id(img_dir, base)\n",
    "            if ip is None:\n",
    "                misses += 1\n",
    "            else:\n",
    "                self.pairs.append((ip, mp))\n",
    "        print(f\"Found {len(self.pairs)} pairs in {split}. Missing matches for {misses} masks.\")\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def _rand_resize(self, img, mask, smin=0.9, smax=1.1):\n",
    "        import cv2, numpy as np, random\n",
    "        h,w = mask.shape\n",
    "        s = random.uniform(smin, smax)\n",
    "        nh, nw = int(h*s), int(w*s)\n",
    "        img2  = cv2.resize(img,  (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
    "        mask2 = cv2.resize(mask, (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
    "        # center crop/pad back to (h,w)\n",
    "        top  = max((nh-h)//2, 0); left = max((nw-w)//2, 0)\n",
    "        img2  = img2[top:top+h, left:left+w]\n",
    "        mask2 = mask2[top:top+h, left:left+w]\n",
    "        if img2.shape[0]!=h or img2.shape[1]!=w:  # pad if needed\n",
    "            pad_h, pad_w = h-img2.shape[0], w-img2.shape[1]\n",
    "            img2  = cv2.copyMakeBorder(img2,0,pad_h,0,pad_w,cv2.BORDER_REFLECT)\n",
    "            mask2 = cv2.copyMakeBorder(mask2,0,pad_h,0,pad_w,cv2.BORDER_REFLECT)\n",
    "        return img2, mask2\n",
    "\n",
    "    def _aug(self, img, mask):\n",
    "        if random.random() < 0.5:\n",
    "            img = np.fliplr(img).copy()\n",
    "            mask = np.fliplr(mask).copy()\n",
    "        if random.random() < 0.5:\n",
    "            img = np.flipud(img).copy()\n",
    "            mask = np.flipud(mask).copy()\n",
    "        if random.random()<0.7:\n",
    "            img, mask = self._rand_resize(img, mask, 0.95, 1.07)\n",
    "        return img, mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ip, mp = self.pairs[i]\n",
    "\n",
    "        # Read RGB input normally\n",
    "        img = cv2.imread(ip, cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(ip)\n",
    "\n",
    "        # Read mask as a single-channel class index map\n",
    "        mask = cv2.imread(mp, cv2.IMREAD_UNCHANGED)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(mp)\n",
    "\n",
    "        # Resize\n",
    "        img  = cv2.resize(img,  (cfg.INPUT_SIZE, cfg.INPUT_SIZE), interpolation=cv2.INTER_LINEAR).copy()\n",
    "        mask = cv2.resize(mask, (cfg.INPUT_SIZE, cfg.INPUT_SIZE), interpolation=cv2.INTER_NEAREST).copy()\n",
    "\n",
    "        # Augment\n",
    "        if self.augment and self.split == \"train\":\n",
    "            img, mask = self._aug(img, mask)\n",
    "\n",
    "        # Convert to tensor (BGR → RGB)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        chw = np.ascontiguousarray(img_rgb.transpose(2, 0, 1))\n",
    "        img_t = torch.from_numpy(chw).float() / 255.0\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "        std  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
    "        img_t = (img_t - mean) / std\n",
    "\n",
    "        mask_t = torch.from_numpy(mask.astype(np.int64))\n",
    "        return img_t, mask_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_loader(img_dir, mask_dir, split, augment, shuffle):\n",
    "    ds = FloodNetDataset(img_dir, mask_dir, split, size=cfg.INPUT_SIZE, augment=augment)\n",
    "    if split == \"train\":\n",
    "        # Build per-sample weights favoring rare classes (presence-based)\n",
    "        weights_by_class = np.array([\n",
    "            0.7853, 0.8961, 0.6962, 0.7499, 0.4871,\n",
    "            0.3552, 0.2736, 2.8701, 2.7268, 0.1598\n",
    "        ], dtype=np.float32)\n",
    "        sample_weights = []\n",
    "        for _, mpath in ds.pairs:\n",
    "            mask = cv2.imread(mpath, cv2.IMREAD_UNCHANGED)\n",
    "            if mask is None:\n",
    "                present_weight = 1.0\n",
    "            else:\n",
    "                vals = np.unique(mask[mask!=255])\n",
    "                present_weight = float(weights_by_class[vals].sum()) if len(vals)>0 else 1.0\n",
    "                present_weight = min(present_weight, 1.4)\n",
    "            sample_weights.append(present_weight)\n",
    "        from torch.utils.data import WeightedRandomSampler\n",
    "        sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "        return ds, DataLoader(\n",
    "            ds,\n",
    "            batch_size=cfg.BATCH_SIZE,\n",
    "            sampler=sampler,\n",
    "            shuffle=False,\n",
    "            num_workers=cfg.NUM_WORKERS,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            drop_last=True,\n",
    "        )\n",
    "    else:\n",
    "        return ds, DataLoader(\n",
    "            ds,\n",
    "            batch_size=cfg.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=cfg.NUM_WORKERS,\n",
    "            pin_memory=False,\n",
    "            persistent_workers=False,\n",
    "            drop_last=False,\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Step: Building dataloaders...\")\n",
    "train_ds, train_dl = make_loader(TRAIN_IMG_DIR, TRAIN_MSK_DIR, \"train\", True, True)\n",
    "val_ds,   val_dl   = make_loader(VAL_IMG_DIR,   VAL_MSK_DIR,   \"val\",   False, False)\n",
    "print(\"Data ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b936cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Building model (DeepLabV3-ResNet50)\n",
      "Downloading: \"https://download.pytorch.org/models/deeplabv3_resnet50_coco-cd0a2569.pth\" to /root/.cache/torch/hub/checkpoints/deeplabv3_resnet50_coco-cd0a2569.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161M/161M [00:00<00:00, 199MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Step: Building model (DeepLabV3-ResNet50)\")\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "try:\n",
    "    from torchvision.models.segmentation import DeepLabV3_ResNet50_Weights\n",
    "    weights = DeepLabV3_ResNet50_Weights.DEFAULT if cfg.USE_PRETRAINED else None\n",
    "    model = deeplabv3_resnet50(weights=weights)\n",
    "except Exception as e:\n",
    "    print(\"  Could not use weights API:\", e)\n",
    "    model = deeplabv3_resnet50(weights=None)\n",
    "\n",
    "try:\n",
    "    in_ch = model.classifier[-1].in_channels\n",
    "    model.classifier[-1] = nn.Conv2d(in_ch, cfg.NUM_CLASSES, 1)\n",
    "except Exception:\n",
    "    in_ch = model.classifier[4].in_channels\n",
    "    model.classifier[4] = nn.Conv2d(in_ch, cfg.NUM_CLASSES, 1)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=cfg.LR)\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "steps_per_epoch = len(train_dl)   # requires train_dl already defined\n",
    "scheduler = OneCycleLR(\n",
    "    opt,\n",
    "    max_lr=cfg.LR,\n",
    "    epochs=cfg.EPOCHS,            # or 15 if you want fixed\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=10.0,\n",
    "    final_div_factor=10.0\n",
    ")\n",
    "\n",
    "\n",
    "# --- Loss: class-weighted CrossEntropy + Dice ---\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class weights derived from validation supports (sqrt-inv-freq, normalized)\n",
    "_class_weights = torch.tensor([\n",
    "    0.7853, 0.8961, 0.6962, 0.7499, 0.4871,\n",
    "    0.3552, 0.2736, 2.8701, 2.7268, 0.1598\n",
    "], dtype=torch.float32, device=device)\n",
    "\n",
    "class ComboLoss(nn.Module):\n",
    "    def __init__(self, num_classes, ignore_index=255, ce_weight=0.7, dice_weight=0.3):\n",
    "        super().__init__()\n",
    "        self.ignore_index = ignore_index\n",
    "        self.ce_weight = ce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce = nn.CrossEntropyLoss(weight=_class_weights, ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # CE part\n",
    "        loss = self.ce(logits, targets)\n",
    "\n",
    "        # Dice part (per-class), masked by ignore_index\n",
    "        with torch.no_grad():\n",
    "            valid = (targets != self.ignore_index).float().unsqueeze(1)\n",
    "        probs = F.softmax(logits, dim=1) * valid\n",
    "        onehot = F.one_hot(targets.clamp(min=0), num_classes=logits.shape[1]).permute(0,3,1,2).float() * valid\n",
    "        intersect = (probs * onehot).sum(dim=(0,2,3))\n",
    "        union = probs.sum(dim=(0,2,3)) + onehot.sum(dim=(0,2,3))\n",
    "        dice = 1.0 - (2.0*intersect + 1e-6) / (union + 1e-6)\n",
    "        dice_loss = dice.mean()\n",
    "\n",
    "        return self.ce_weight*loss + self.dice_weight*dice_loss\n",
    "\n",
    "# right above ComboLoss\n",
    "weights = torch.tensor([\n",
    "    0.7853, 0.8961, 0.6962, 0.7499, 0.4871,\n",
    "    0.3552, 0.2736, 2.8701, 2.7268, 0.1598\n",
    "], dtype=torch.float32, device=device)\n",
    "weights[7] *= 0.7    # vehicles\n",
    "weights[8] *= 0.8    # pools\n",
    "_class_weights = weights\n",
    "crit = ComboLoss(num_classes=cfg.NUM_CLASSES, ignore_index=255, ce_weight=0.85, dice_weight=0.15)\n",
    "print(\"Model ready on\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c26e361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in batch: tensor([2, 4, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "print(\"Unique labels in batch:\", torch.unique(yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Train/Eval...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080c3a2e469542938f461966cf1aa48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01  train_loss=1.7101  val_loss=0.7792  val_acc=0.7788\n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae1988e74d64701951d2b0c61b217fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02  train_loss=0.8663  val_loss=1.5356  val_acc=0.6666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c296868ace0f4de0b26454009b75b419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a5f2f32e160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    Exception ignored in: if w.is_alive():\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a5f2f32e160> \n",
      " Traceback (most recent call last):\n",
      "   File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "       self._shutdown_workers() \n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "^    ^if w.is_alive():^\n",
      "^ ^ ^ ^ ^ ^ ^ ^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^ ^ ^ ^ ^ \n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7a5f2f32e160>^\n",
      "^Traceback (most recent call last):\n",
      "^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "^    \n",
      "self._shutdown_workers()AssertionError\n",
      ": can only test a child process  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "\n",
      "    if w.is_alive():Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7a5f2f32e160> \n",
      " Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1664, in __del__\n",
      "       self._shutdown_workers() \n",
      " ^  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 1647, in _shutdown_workers\n",
      "    ^if w.is_alive():^\n",
      " ^^ ^  ^^  ^ ^^^^^^\n",
      "^  File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n",
      "^ ^ ^ ^ \n",
      "   File \"/usr/lib/python3.12/multiprocessing/process.py\", line 160, in is_alive\n",
      "      assert self._parent_pid == os.getpid(), 'can only test a child process' \n",
      "      ^ ^ ^ ^ ^^  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^: ^can only test a child process^\n",
      "^^^^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03  train_loss=0.6892  val_loss=0.5866  val_acc=0.8442\n",
      "Saved best model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933c7062b25e490ea4fa7878f8cb2a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04  train_loss=0.6024  val_loss=0.8265  val_acc=0.7861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c493ec4662a4347908d034afe765ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05  train_loss=0.5721  val_loss=0.8358  val_acc=0.8165\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm.auto import tqdm\n",
    "def train_one_epoch(epoch):\n",
    "    model.train(); total=0.0\n",
    "    for x,y in tqdm(train_dl, desc=f\"Epoch {epoch} • Training\", leave=False):\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        out = model(x)['out']\n",
    "        out_dict = model(x)\n",
    "        main_logits = out_dict['out']\n",
    "        aux_logits  = out_dict.get('aux', None)\n",
    "\n",
    "        loss = crit(main_logits, y)\n",
    "        if aux_logits is not None:\n",
    "            loss = loss + 0.2 * nn.CrossEntropyLoss(ignore_index=255)(aux_logits, y)\n",
    "        loss.backward(); opt.step(); scheduler.step()\n",
    "        total += loss.item()*x.size(0)\n",
    "    return total/len(train_ds)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate():\n",
    "    model.eval(); total=0.0; accs=[]\n",
    "    for x,y in val_dl:\n",
    "        x,y=x.to(device),y.to(device)\n",
    "        o = model(x)['out']; loss = crit(o,y)\n",
    "        total += loss.item()*x.size(0)\n",
    "        accs.append((o.argmax(1)==y).float().mean().item())\n",
    "    return total/len(val_ds), float(np.mean(accs)) if accs else 0.0\n",
    "\n",
    "print(\"Step: Train/Eval...\")\n",
    "best=1e9\n",
    "\n",
    "for e in range(1, 6):\n",
    "    tl = train_one_epoch(e)\n",
    "    vl, va = evaluate()\n",
    "    print(f\"Epoch {e:02d}  train_loss={tl:.4f}  val_loss={vl:.4f}  val_acc={va:.4f}\")\n",
    "    if vl<best:\n",
    "        best=vl\n",
    "        torch.save(model.state_dict(), Path(cfg.OUT_DIR)/\"best_model.pt\")\n",
    "        print(\"Saved best model\")\n",
    "print(\"Training done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813a895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3000, 4000) dtype: uint8 unique values: [5]\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "sample_mask = sorted(glob(str(Path(TRAIN_MSK_DIR) / \"*_lab.png\")))[0]\n",
    "mask = cv2.imread(sample_mask, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "print(\"Shape:\", mask.shape, \"dtype:\", mask.dtype, \"unique values:\", np.unique(mask)[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Metrics on val\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.465     0.204     0.284   2671061\n",
      "           1      0.769     0.935     0.844   2051102\n",
      "           2      0.828     0.569     0.674   3398436\n",
      "           3      0.636     0.854     0.729   2929103\n",
      "           4      0.843     0.733     0.784   6942688\n",
      "           5      0.649     0.741     0.692  13053570\n",
      "           6      0.797     0.784     0.790  22003006\n",
      "           7      0.466     0.608     0.528    199948\n",
      "           8      0.524     0.571     0.547    221510\n",
      "           9      0.880     0.886     0.883  64494376\n",
      "\n",
      "    accuracy                          0.817 117964800\n",
      "   macro avg      0.686     0.689     0.675 117964800\n",
      "weighted avg      0.817     0.817     0.814 117964800\n",
      "\n",
      "Metrics done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "@torch.no_grad()\n",
    "def metrics_report(loader, split=\"val\"):\n",
    "    model.eval()\n",
    "    preds_all, gts_all = [], []\n",
    "    for x,y in loader:\n",
    "        x = x.to(device)\n",
    "        p = model(x)['out'].argmax(1).cpu().numpy().reshape(-1)\n",
    "        g = y.numpy().reshape(-1)\n",
    "        m = g!=255\n",
    "        preds_all.append(p[m]); gts_all.append(g[m])\n",
    "    if not preds_all:\n",
    "        print(\"No batches to score.\"); return\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    gts_all = np.concatenate(gts_all)\n",
    "\n",
    "    labels = list(range(cfg.NUM_CLASSES))\n",
    "    cm = confusion_matrix(gts_all, preds_all, labels=labels)\n",
    "    rep = classification_report(\n",
    "        gts_all, preds_all,\n",
    "        labels=labels,\n",
    "        target_names=[str(i) for i in labels],\n",
    "        digits=3,\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(rep)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_tta(x):\n",
    "    ys = []\n",
    "    for flip in [(False,False),(True,False),(False,True),(True,True)]:\n",
    "        xf = torch.flip(x, dims=[2] if flip[0] else [])  # H\n",
    "        xf = torch.flip(xf, dims=[3] if flip[1] else []) # W\n",
    "        logits = model(xf)['out']\n",
    "        # unflip logits back\n",
    "        if flip[0]: logits = torch.flip(logits, dims=[2])\n",
    "        if flip[1]: logits = torch.flip(logits, dims=[3])\n",
    "        ys.append(logits)\n",
    "    return torch.stack(ys).mean(0)  # logit-avg\n",
    "\n",
    "\n",
    "print(\"Step: Metrics on val\")\n",
    "metrics_report(val_dl, \"val\")\n",
    "print(\"Metrics done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709749a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: mIoU (torchmetrics, GPU)\n",
      "mIoU (GPU): 0.5884\n",
      "mIoU done (GPU)\n"
     ]
    }
   ],
   "source": [
    "print(\"Step: mIoU (torchmetrics, GPU)\")\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "# (Optional) always eval the best checkpoint\n",
    "best_ckpt = Path(cfg.OUT_DIR) / \"best_model.pt\"\n",
    "if best_ckpt.exists():\n",
    "    model.load_state_dict(torch.load(best_ckpt, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "try:\n",
    "    from torchmetrics.classification import MulticlassJaccardIndex\n",
    "except Exception:\n",
    "    from torchmetrics import JaccardIndex as MulticlassJaccardIndex  # older torchmetrics\n",
    "\n",
    "# ---- Overall mIoU on GPU ----\n",
    "miou = MulticlassJaccardIndex(num_classes=cfg.NUM_CLASSES, ignore_index=255).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_miou_gpu(loader):\n",
    "    miou.reset()\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        preds = model(x)['out'].argmax(1)\n",
    "        logits = predict_tta(x)\n",
    "        preds = logits.argmax(1)\n",
    "        miou.update(preds, y)\n",
    "    val = miou.compute()\n",
    "    val = val.item() if hasattr(val, \"item\") else float(val)\n",
    "    print(f\"mIoU (GPU): {val:.4f}\")\n",
    "\n",
    "compute_miou_gpu(val_dl)\n",
    "print(\"mIoU done (GPU)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LusWZn0EUGym",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: mIoU (torchmetrics)\n",
      "Per-class IoU: [0.14961107 0.719854   0.721705   0.44349182 0.7654764  0.62859505\n",
      " 0.7670748  0.36605206 0.49738175 0.8247999 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step: mIoU (torchmetrics)\")\n",
    "try:\n",
    "    from torchmetrics.classification import MulticlassJaccardIndex\n",
    "except Exception:\n",
    "    from torchmetrics import JaccardIndex as MulticlassJaccardIndex\n",
    "\n",
    "miou_pc = MulticlassJaccardIndex(num_classes=cfg.NUM_CLASSES, ignore_index=255, average=None).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def per_class_iou_gpu(loader):\n",
    "    miou_pc.reset()\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "        preds = model(x)['out'].argmax(1)\n",
    "        logits = predict_tta(x)\n",
    "        preds = logits.argmax(1)\n",
    "        miou_pc.update(preds, y)\n",
    "    vec = miou_pc.compute()  # shape [num_classes] on device\n",
    "    print(\"Per-class IoU:\", vec.detach().cpu().numpy())\n",
    "\n",
    "per_class_iou_gpu(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195025e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Overlay samples\n",
      "Saved overlays to outputs_floodnet_supervised/overlays_val\n",
      "Overlay saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mask_to_color(mask_np):\n",
    "    out = np.zeros((*mask_np.shape,3), np.uint8)\n",
    "    for i,c in enumerate(CLASS_COLORS):\n",
    "        out[mask_np==i] = c\n",
    "    return out\n",
    "\n",
    "def overlay(img_bgr, mask_idx, alpha=0.45):\n",
    "    color = mask_to_color(mask_idx)\n",
    "    return cv2.addWeighted(img_bgr, 1-alpha, color, alpha, 0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def save_overlays(n=6):\n",
    "    model.eval()\n",
    "    try:\n",
    "        x,y = next(iter(val_dl))\n",
    "    except StopIteration:\n",
    "        print(\"No val batches to visualize.\"); return\n",
    "    o = model(x.to(device))['out'].argmax(1).cpu().numpy()\n",
    "    x_np = x.numpy()\n",
    "    mean = np.array([0.485,0.456,0.406]).reshape(1,3,1,1)\n",
    "    std  = np.array([0.229,0.224,0.225]).reshape(1,3,1,1)\n",
    "    x_np = np.clip(x_np*std + mean, 0, 1)\n",
    "    outdir = Path(cfg.OUT_DIR)/\"overlays_val\"; outdir.mkdir(parents=True, exist_ok=True)\n",
    "    k=min(n, x_np.shape[0])\n",
    "    for i in range(k):\n",
    "        img = (x_np[i].transpose(1,2,0)*255).astype(np.uint8)[:,:,::-1]\n",
    "        gt = y[i].numpy()\n",
    "        ov_pred = overlay(img, o[i])\n",
    "        ov_gt   = overlay(img, gt)\n",
    "        cv2.imwrite(str(outdir/f\"{i:02d}_pred.png\"), ov_pred)\n",
    "        cv2.imwrite(str(outdir/f\"{i:02d}_gt.png\"), ov_gt)\n",
    "    print(\"Saved overlays to\", outdir)\n",
    "\n",
    "print(\"Step: Overlay samples\")\n",
    "save_overlays(6)\n",
    "print(\"Overlay saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2e9c8",
   "metadata": {
    "id": "67c2e9c8"
   },
   "source": [
    "# Task\n",
    "Tune the hyperparameters of the model using Bayesian optimization to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb764ff",
   "metadata": {
    "id": "4eb764ff"
   },
   "source": [
    "## Install necessary libraries\n",
    "\n",
    "### Subtask:\n",
    "Install libraries for Bayesian optimization (e.g., `optuna`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343a0636",
   "metadata": {
    "id": "343a0636"
   },
   "source": [
    "**Reasoning**:\n",
    "The subtask is to install the `optuna` library. This can be done using pip in a code block.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc68c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install optuna -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a22971",
   "metadata": {
    "id": "37a22971"
   },
   "source": [
    "## Define the objective function\n",
    "\n",
    "### Subtask:\n",
    "Create a function that takes hyperparameters as input, trains the model for a few epochs, evaluates it on the validation set, and returns the validation loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8cdb85",
   "metadata": {
    "id": "3b8cdb85"
   },
   "source": [
    "**Reasoning**:\n",
    "Define the objective function for Optuna that will suggest hyperparameters, build and train the model with those hyperparameters for a limited number of epochs, and return the validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [2, 4, 8])\n",
    "    epochs = 5  # Limit epochs for faster trials\n",
    "\n",
    "    # Adapt CFG\n",
    "    cfg.LR = lr\n",
    "    cfg.BATCH_SIZE = batch_size\n",
    "    cfg.EPOCHS = epochs\n",
    "\n",
    "    # Recreate dataloaders with new batch size\n",
    "    # Need to re-create the dataset instances as well to use the updated cfg.BATCH_SIZE\n",
    "    train_ds, train_dl = make_loader(TRAIN_IMG_DIR, TRAIN_MSK_DIR, \"train\", True, True)\n",
    "    val_ds,   val_dl   = make_loader(VAL_IMG_DIR,   VAL_MSK_DIR,   \"val\",   False, False)\n",
    "\n",
    "\n",
    "    # Recreate model and optimizer\n",
    "    model = deeplabv3_resnet50(weights=None)\n",
    "    try:\n",
    "        in_ch = model.classifier[-1].in_channels\n",
    "        model.classifier[-1] = nn.Conv2d(in_ch, cfg.NUM_CLASSES, 1)\n",
    "    except Exception:\n",
    "        in_ch = model.classifier[4].in_channels\n",
    "        model.classifier[4] = nn.Conv2d(in_ch, cfg.NUM_CLASSES, 1)\n",
    "\n",
    "    model.to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=cfg.LR)\n",
    "\n",
    "    # Recreate scheduler\n",
    "    steps_per_epoch = len(train_dl)\n",
    "    scheduler = OneCycleLR(\n",
    "        opt,\n",
    "        max_lr=cfg.LR,\n",
    "        epochs=cfg.EPOCHS,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=10.0,\n",
    "        final_div_factor=10.0\n",
    "    )\n",
    "\n",
    "    # Recreate loss function (uses _class_weights which is global)\n",
    "    crit = ComboLoss(num_classes=cfg.NUM_CLASSES, ignore_index=255, ce_weight=0.85, dice_weight=0.15)\n",
    "\n",
    "\n",
    "    # Train the model for the limited number of epochs\n",
    "    for epoch in range(1, cfg.EPOCHS + 1):\n",
    "        train_loss = train_one_epoch(epoch)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = evaluate()\n",
    "\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadba87",
   "metadata": {
    "id": "ebadba87"
   },
   "source": [
    "## Define the hyperparameter search space\n",
    "\n",
    "### Subtask:\n",
    "Specify the range or distribution for each hyperparameter you want to tune (e.g., learning rate, batch size).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef42f4",
   "metadata": {
    "id": "67ef42f4"
   },
   "source": [
    "**Reasoning**:\n",
    "Review the objective function to identify the hyperparameters being tuned and their ranges/distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters and their suggested ranges/distributions from the objective function:\n",
      "Learning Rate (lr): Suggested range [1e-5, 1e-3] with log scaling.\n",
      "Batch Size (batch_size): Suggested categories [2, 4, 8].\n",
      "Epochs (epochs): Fixed at 5 for faster trials.\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperparameters and their suggested ranges/distributions from the objective function:\")\n",
    "print(f\"Learning Rate (lr): Suggested range [1e-5, 1e-3] with log scaling.\")\n",
    "print(f\"Batch Size (batch_size): Suggested categories [2, 4, 8].\")\n",
    "print(f\"Epochs (epochs): Fixed at 5 for faster trials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78c7c5",
   "metadata": {
    "id": "fa78c7c5"
   },
   "source": [
    "## Set up and run the bayesian optimization study\n",
    "\n",
    "### Subtask:\n",
    "Set up and run the bayesian optimization study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dec923",
   "metadata": {
    "id": "01dec923"
   },
   "source": [
    "**Reasoning**:\n",
    "Import optuna, create a study, and run the optimization process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e60eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-08 19:05:18,131] A new study created in memory with name: floodnet_hpo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian optimization study...\n",
      "Found 1460 pairs in train. Missing matches for 0 masks.\n",
      "Found 450 pairs in val. Missing matches for 0 masks.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c88e4b1365d47f093d622c62145dc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 • Training:   0%|          | 0/730 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-10-08 19:12:48,565] Trial 0 failed with parameters: {'lr': 2.301604446008178e-05, 'batch_size': 4} because of the following error: ValueError('Tried to step 3651 times. The specified number of total steps is 3650').\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipython-input-2708244926.py\", line 51, in objective\n",
      "    train_loss = train_one_epoch(epoch)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipython-input-1515390628.py\", line 15, in train_one_epoch\n",
      "    loss.backward(); opt.step(); scheduler.step()\n",
      "                                 ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 207, in step\n",
      "    values = self.get_lr()\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 2131, in get_lr\n",
      "    raise ValueError(\n",
      "ValueError: Tried to step 3651 times. The specified number of total steps is 3650\n",
      "[W 2025-10-08 19:12:48,567] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tried to step 3651 times. The specified number of total steps is 3650",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2569773115.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"floodnet_hpo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"minimize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bayesian optimization study finished.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     ):\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-2708244926.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Train the model for the limited number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Evaluate the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-1515390628.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maux_logits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_DEPRECATION_WARNING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mget_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep_num\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2132\u001b[0m                 \u001b[0;34mf\"Tried to step {step_num} times. The specified number of total steps is {self.total_steps}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to step 3651 times. The specified number of total steps is 3650"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "print(\"Starting Bayesian optimization study...\")\n",
    "\n",
    "study = optuna.create_study(study_name=\"floodnet_hpo\", direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Bayesian optimization study finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8138baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: Identify the best hyperparameters from the interrupted study...\n",
      "Best hyperparameters found so far:\n",
      "  lr: 1.0226771675829212e-05\n",
      "  batch_size: 8\n",
      "\n",
      "cfg updated with best hyperparameters.\n"
     ]
    }
   ],
   "source": [
    "print(\"Step: Identify the best hyperparameters from the interrupted study...\")\n",
    "\n",
    "# Assuming the study object 'study' is still available from the previous run.\n",
    "# If not, you would need to load it from persistent storage if you had saved it.\n",
    "if 'study' in locals() and study.best_trial:\n",
    "    best_params = study.best_trial.params\n",
    "    print(\"Best hyperparameters found so far:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    # You can now use these best_params for the final training\n",
    "    # For example, update the cfg object:\n",
    "    cfg.LR = best_params['lr']\n",
    "    cfg.BATCH_SIZE = best_params['batch_size']\n",
    "    # Note: We will use the original number of epochs for the final training,\n",
    "    # not the limited number used in the objective function.\n",
    "    cfg.EPOCHS = 15 # Set back to the original or desired number of epochs for final training\n",
    "\n",
    "    print(\"\\ncfg updated with best hyperparameters.\")\n",
    "\n",
    "elif 'study' in locals() and not study.best_trial:\n",
    "    print(\"No trials were completed in the study.\")\n",
    "    print(\"Please consider running the optimization for at least one trial.\")\n",
    "else:\n",
    "    print(\"The 'study' object is not available. Please run the optimization cell first.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
